{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pixel Based Metrics for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, the following pixel-based statistical features are calculated.\n",
    "Images are then tried to be classified based on these features.\n",
    "\n",
    "#### Computed Features\n",
    "* Range, mean, std on red, green and blue channel\n",
    "* range, mean, std on magnitude of Sobel gradients for r, g and b channel\n",
    "* Energy, correlation, homogeneity on GLCM of grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import pickle\n",
    "\n",
    "import utils\n",
    "\n",
    "from scipy.ndimage import sobel\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an arbitrary example image\n",
    "train_dir = join('..', '..', 'data', 'curated', 'roofs_train')\n",
    "materials = {'concrete_cement':0, 'healthy_metal':1, 'incomplete':2, 'irregular_metal':3, 'other':4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Image Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Image Channels and Gradient Magnitude Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = join(train_dir, 'other', '7a307a06.tif')\n",
    "img = io.imread(train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize = (16, 5))\n",
    "\n",
    "for k in [ax1, ax2, ax3, ax4]:\n",
    "    k.axes.get_xaxis().set_visible(False)\n",
    "    k.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "ax1.imshow(img, cmap='gray')\n",
    "ax1.set_title(\"Original\")\n",
    "ax2.imshow(img[:, :, 0], cmap='Reds')\n",
    "ax2.set_title(\"Red\")\n",
    "ax3.imshow(img[:, :, 1], cmap='Greens')\n",
    "ax3.set_title(\"Green\")\n",
    "ax4.imshow(img[:, :, 2], cmap='Blues')\n",
    "ax4.set_title(\"Blue\")\n",
    "fig.suptitle(\"Channels original image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Gradient Magnitude Images based on Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_layers(img):\n",
    "    sob = np.zeros(img.shape)    \n",
    "    for layer in range(img.shape[2]):\n",
    "        sx = sobel(img[:, :, layer].astype('int32'), axis=0, mode='constant')\n",
    "        sy = sobel(img[:, :, layer].astype('int32'), axis=1, mode='constant')\n",
    "        sob[:, :, layer] = np.hypot(sx, sy)\n",
    "    return sob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sob = sobel_layers(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize = (16, 5))\n",
    "\n",
    "for k in [ax1, ax2, ax3]:\n",
    "    k.axes.get_xaxis().set_visible(False)\n",
    "    k.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    \n",
    "ax1.imshow(sob[:, :, 0], cmap='Reds')\n",
    "ax1.set_title(\"Red\")\n",
    "ax2.imshow(sob[:, :, 1], cmap='Greens')\n",
    "ax2.set_title(\"Green\")\n",
    "ax3.imshow(sob[:, :, 2], cmap='Blues')\n",
    "ax3.set_title(\"Blue\")\n",
    "fig.suptitle(\"Gradient magnitudes with Sobel filtering on channels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics on Original and Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistics(img, sob):\n",
    "    \"\"\" \n",
    "    Expects image as numpy array.\n",
    "    Calculates basic image statistics (variance, std, range, mean)\n",
    "    \"\"\"\n",
    "    # Select only those pixels that belong to the roof (i.e. mask the image)\n",
    "    img_arr = img[:, :, :3][img[:, :, 3] > 0]\n",
    "\n",
    "    mean_rgb = img_arr.mean(0)\n",
    "    std_rgb = img_arr.std(0)\n",
    "    ptp_rgb = img_arr.ptp(0) #peak-to-peak = range\n",
    "    \n",
    "    # Calculate statistics on gradient (Sobel) image\n",
    "    sob_arr = sob[:, :, :3][sob[:, :, 3] > 0]\n",
    "\n",
    "    mean_sob = sob_arr.mean(0)\n",
    "    std_sob = sob_arr.std(0)\n",
    "    ptp_sob = sob_arr.ptp(0)\n",
    "\n",
    "    return mean_rgb, std_rgb, ptp_rgb, mean_sob, std_sob, ptp_sob\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(img, sob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GLCM features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For textural features, convert the image to grayscale and calculate energy, correlation and homogeneity features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io, color, img_as_ubyte\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "from sklearn.metrics.cluster import entropy\n",
    "\n",
    "def glcm_feats(img):\n",
    "    grayImg = img_as_ubyte(color.rgb2gray(img))\n",
    "\n",
    "    distances = [1, 2, 3]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    properties = ['energy', 'correlation', 'homogeneity']\n",
    "\n",
    "    glcm = greycomatrix(grayImg, \n",
    "                        distances=distances, \n",
    "                        angles=angles,\n",
    "                        symmetric=True,\n",
    "                        normed=True)\n",
    "    glcm_en = greycoprops(glcm, 'energy')\n",
    "    glcm_co = greycoprops(glcm, 'correlation')\n",
    "    glcm_ho = greycoprops(glcm, 'homogeneity')\n",
    "    \n",
    "    return glcm_en, glcm_co, glcm_ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glcm_feats(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compute above Features on all labeled images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk through all images, compute the features and collect them in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dir = join('..', '..', 'data', 'data2', 'mixco_3', 'roofs_train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(train_dir):\n",
    "    \n",
    "    # Initialize a dataframe for the features    \n",
    "    columns = ['id', 'label',\n",
    "               'mean_rgb', 'std_rgb', 'ptp_rgb',\n",
    "               'mean_sob', 'std_sob', 'ptp_sob',\n",
    "               'glcm_en', 'glcm_co', 'glcm_ho']\n",
    "    df_features = pd.DataFrame(columns=columns)\n",
    "\n",
    "    data = []\n",
    "    # Walk through all images\n",
    "    for material in materials.keys():\n",
    "        material_fp = join(train_dir, material)\n",
    "        print(material_fp)\n",
    "        for root, dirs, files in os.walk(material_fp):\n",
    "            for file in files:\n",
    "                img_fp = join(material_fp, file)\n",
    "                label = materials[material]\n",
    "                id = file.split('.')[0] # retrieve id from filename\n",
    "                print(id, \"labeled as\", material, \":\", label)\n",
    "                \n",
    "                img = io.imread(img_fp)\n",
    "                sob = sobel_layers(img)\n",
    "                \n",
    "                mean_rgb, std_rgb, ptp_rgb, mean_sob, std_sob, ptp_sob = statistics(img, sob)\n",
    "                glcm_en, glcm_co, glcm_ho = glcm_feats(img)\n",
    "\n",
    "                data.append({'id': id ,\n",
    "                             'mean_r': mean_rgb[0], 'mean_g': mean_rgb[1], 'mean_b': mean_rgb[2],\n",
    "                             'std_r': std_rgb[0], 'std_g': std_rgb[1], 'std_b': std_rgb[2],\n",
    "                             'ptp_r': ptp_rgb[0], 'ptp_g': ptp_rgb[1], 'ptp_b': ptp_rgb[2],\n",
    "                             'mean_sob_r': mean_sob[0], 'mean_sob_g': mean_sob[1], 'mean_sob_b': mean_sob[2],\n",
    "                             'std_sob_r': std_sob[0], 'std_sob_g': std_sob[1], 'std_sob_b': std_sob[2],\n",
    "                             'ptp_sob_r': ptp_sob[0], 'ptp_sob_g': ptp_sob[1], 'ptp_sob_b': ptp_sob[2],\n",
    "                             'glcm_en': glcm_en, 'glcm_co': glcm_co, 'glcm_ho': glcm_ho,\n",
    "                             'label': label})\n",
    "    \n",
    "    df_features = pd.DataFrame(data)\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pickle_path = join('..', '..', 'pickles')\n",
    "compute_anew = False\n",
    "\n",
    "if compute_anew == True:\n",
    "    pb_features = calculate_features(train_dir)\n",
    "    with open(join(pickle_path, 'pb_features.pkl'), 'wb') as f:\n",
    "        pickle.dump(pb_features, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Classification based on above features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = join('..', '..', 'pickles')\n",
    "with open(join(pickle_path, 'pb_features.pkl'), 'rb') as f:\n",
    "    pb_features = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select features that shall be taken into account for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feats = ['mean_r', 'mean_g', 'mean_b',\n",
    "                 'std_r', 'std_g', 'std_b',\n",
    "                 'ptp_r', 'ptp_g', 'ptp_b',\n",
    "                 'mean_sob_r', 'mean_sob_g', 'mean_sob_b',\n",
    "                 'std_sob_r', 'std_sob_g', 'std_sob_b',\n",
    "                 'ptp_sob_r', 'ptp_sob_g', 'ptp_sob_b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = pb_features[selected_feats].to_numpy()\n",
    "#feature_matrix = np.column_stack(feature_matrix).transpose()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(feature_matrix)\n",
    "feature_matrix_scaled = scaler.transform(feature_matrix)\n",
    "\n",
    "labels = pb_features['label'].to_numpy().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(feature_matrix,\n",
    "                                                                            labels,\n",
    "                                                                            test_size=0.33,\n",
    "                                                                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='scale', probability=True, C=100, decision_function_shape='ovr')\n",
    "clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = clf.predict(features_test)\n",
    "cm = confusion_matrix(labels_test, predicted_labels)\n",
    "\n",
    "row_sums = cm.sum(axis=1, keepdims=True)\n",
    "cm_norm = cm / row_sums\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8.5, 8.5))\n",
    "im, cbar = utils.heatmap(cm_norm,  materials.keys(), materials.keys(), ax=ax,\n",
    "                         cmap=\"GnBu\")\n",
    "texts = utils.annotate_heatmap(im)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fname = join('..', 'documentation', 'figures', 'results', 'pixel_based_cm.png')\n",
    "fig.savefig(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Statistical Scores With Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate(clf, feature_matrix_scaled, labels,\n",
    "                            cv=5, scoring=('f1_macro', 'f1_micro', 'accuracy', 'balanced_accuracy', 'log_loss'),\n",
    "                            n_jobs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(labels_test, predicted_labels, average=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
