{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. For a single region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Read saved feature matrix and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'mixco_3'\n",
    "\n",
    "pickle_path = join('..', '..', 'pickles')\n",
    "with open(join(pickle_path, 'resnet50_features_' + region + '_train.pkl'), 'rb') as f:\n",
    "    features_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Convert the features into a matrix and the labels into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = features_train['features'].to_numpy()\n",
    "feature_matrix = np.column_stack(feat_matrix).transpose()\n",
    "\n",
    "labels = features_train['label'].to_numpy().astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Split data into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(feature_matrix,\n",
    "                                                                            labels,\n",
    "                                                                            test_size=0.33,\n",
    "                                                                            random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3. Train a classifier on the training set and save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='scale', probability=True, C=100, decision_function_shape='ovr')\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "with open(join(pickle_path, 'classifier.pkl' ), 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4. Predict labels on the validation set according to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_labels = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5. Calculate and plot (to do) the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[17  0  0  0]\n",
      " [ 1 14  2  1]\n",
      " [ 1  0 16  0]\n",
      " [ 1  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(labels_test, predicted_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01432318 0.97646168 0.00248714 0.006728  ] 1\n",
      "[0.03435104 0.03802011 0.92495716 0.0026717 ] 2\n",
      "[0.0853879  0.04645862 0.85464752 0.01350596] 2\n",
      "[0.51623924 0.33767721 0.09757833 0.04850522] 0\n",
      "[0.00828789 0.91065825 0.0092641  0.07178976] 1\n",
      "[0.14554093 0.80591284 0.02137687 0.02716936] 1\n",
      "[0.01650321 0.00432187 0.97576329 0.00341163] 2\n",
      "[0.0604639  0.40781854 0.49668187 0.03503569] 1\n",
      "[0.97175708 0.02143286 0.00483211 0.00197796] 0\n",
      "[0.91126869 0.06183233 0.01316497 0.01373401] 0\n",
      "[0.94736647 0.02657177 0.01383606 0.0122257 ] 0\n",
      "[0.02610183 0.02721261 0.94458762 0.00209793] 2\n",
      "[0.00822071 0.00355633 0.98385746 0.0043655 ] 2\n",
      "[0.04418412 0.80551715 0.05941063 0.0908881 ] 1\n",
      "[0.01977288 0.01959542 0.95859802 0.00203367] 2\n",
      "[0.76535632 0.07237136 0.14912748 0.01314483] 0\n",
      "[0.64087794 0.2706998  0.07687663 0.01154564] 0\n",
      "[0.00965878 0.00360163 0.98167693 0.00506266] 2\n",
      "[0.84908375 0.04678598 0.03507736 0.06905291] 0\n",
      "[0.91758135 0.02803361 0.04411353 0.01027151] 0\n",
      "[0.01330783 0.91378982 0.01486418 0.05803817] 1\n",
      "[0.04465333 0.15612815 0.78929627 0.00992225] 2\n",
      "[0.00206567 0.98870709 0.00199556 0.00723168] 1\n",
      "[0.01814299 0.04861074 0.9203313  0.01291497] 2\n",
      "[0.77088593 0.01867458 0.18812059 0.0223189 ] 0\n",
      "[0.03412084 0.0046519  0.95722756 0.0039997 ] 2\n",
      "[0.98745638 0.00884582 0.00269492 0.00100288] 0\n",
      "[0.99119412 0.00430995 0.00264217 0.00185376] 0\n",
      "[0.02447388 0.3797452  0.58070396 0.01507696] 1\n",
      "[0.03049884 0.01709294 0.94655797 0.00585025] 2\n",
      "[0.97495581 0.01112763 0.00401699 0.00989957] 0\n",
      "[0.00418787 0.01150892 0.98159391 0.0027093 ] 2\n",
      "[0.96163767 0.00986899 0.00309088 0.02540247] 0\n",
      "[0.57669672 0.22798721 0.03922363 0.15609245] 4\n",
      "[0.00500838 0.0040127  0.98934391 0.00163501] 2\n",
      "[0.06357008 0.62627447 0.23452557 0.07562988] 1\n",
      "[0.96185194 0.01562365 0.0181608  0.00436361] 0\n",
      "[0.06216435 0.03030347 0.90115095 0.00638123] 2\n",
      "[0.93050084 0.00788646 0.05834713 0.00326557] 0\n",
      "[0.00925627 0.91972724 0.03104377 0.03997273] 1\n",
      "[0.05954351 0.87824634 0.03106116 0.03114898] 1\n",
      "[0.03773667 0.83484867 0.04400408 0.08341058] 1\n",
      "[0.70853568 0.03194669 0.1958091  0.06370853] 0\n",
      "[0.01198181 0.18963924 0.0156627  0.78271625] 1\n",
      "[0.00526711 0.98938534 0.00310221 0.00224534] 1\n",
      "[0.49580074 0.34716233 0.108667   0.04836993] 1\n",
      "[0.41970314 0.03841818 0.53826667 0.003612  ] 2\n",
      "[0.01709538 0.0152636  0.96537205 0.00226897] 2\n",
      "[0.96809197 0.01965571 0.00631182 0.0059405 ] 0\n",
      "[0.49475203 0.07165509 0.41611795 0.01747493] 2\n",
      "[0.07139548 0.83436266 0.06503763 0.02920423] 1\n",
      "[0.01155914 0.92045834 0.02166173 0.04632078] 1\n",
      "[0.00985345 0.80558334 0.01187294 0.17269027] 1\n"
     ]
    }
   ],
   "source": [
    "pred_probas = clf.predict_proba(features_test)\n",
    "\n",
    "for i in range(len(predicted_labels)):\n",
    "    print(pred_probas[i], labels_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Classifier Using All Regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Load all available training features into one big dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['borde_rural', 'borde_soacha', 'mixco_1_and_ebenezer', 'mixco_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No available training features for region  borde_rural\n",
      "No available training features for region  borde_soacha\n",
      "No available training features for region  mixco_1_and_ebenezer\n"
     ]
    }
   ],
   "source": [
    "columns = ['id', 'features', 'label']\n",
    "features_train_global = pd.DataFrame(columns=columns)\n",
    "\n",
    "for region in regions:\n",
    "    try:\n",
    "        with open(join(pickle_path, 'resnet50_features_' + region + '_train.pkl'), 'rb') as f:\n",
    "            features_local = pickle.load(f)\n",
    "            features_local.head()\n",
    "            features_train_global = pd.concat([features_train_global, features_local])\n",
    "    except:\n",
    "        print(\"No available training features for region \", region)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a classifier with this giant dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13849,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gloabal_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='scale', probability=True, C=100, decision_function_shape='ovr')\n",
    "clf.fit(global_feature_matrix, gloabal_labels)\n",
    "\n",
    "with open(join(pickle_path, 'classifier_global.pkl' ), 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
