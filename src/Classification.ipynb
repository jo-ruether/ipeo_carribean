{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. For a single region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Read saved feature matrix and corresponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'borde_rural'\n",
    "\n",
    "pickle_path = join('..', '..', 'pickles')\n",
    "with open(join(pickle_path, 'resnet50_features_' + region + '_train.pkl'), 'rb') as f:\n",
    "    df_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Convert the features into a matrix and the labels into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = df_train['features'].to_numpy()\n",
    "feature_matrix = np.column_stack(feature_matrix).transpose()\n",
    "\n",
    "labels = df_train['label'].to_numpy().astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3 Split data into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(feature_matrix,\n",
    "                                                                            labels,\n",
    "                                                                            test_size=0.33,\n",
    "                                                                            random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3. Train a classifier on the training set and save it to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(gamma='scale', probability=True, C=100, decision_function_shape='ovr')\n",
    "clf.fit(features_train, labels_train)\n",
    "\n",
    "with open(join(pickle_path, 'classifier_densenet201_max.pkl' ), 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4. Predict labels on the validation set according to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_labels = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5. Calculate and plot (to do) the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 44   4   6   8   0]\n",
      " [  2 658   1 109   0]\n",
      " [  6   5  34  36   0]\n",
      " [  2 114  13 393   0]\n",
      " [  0   1   0   1   0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(labels_test, predicted_labels)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93800929 0.01484652 0.01814413 0.00568303 0.02331702] 0\n",
      "[9.08252507e-04 2.45963026e-03 3.79420015e-03 9.86714228e-01\n",
      " 6.12368935e-03] 3\n",
      "[0.8838209  0.04758416 0.00903683 0.00636294 0.05319517] 0\n",
      "[0.64379693 0.01603544 0.29894523 0.02332422 0.01789818] 0\n",
      "[0.03330799 0.09994666 0.0182777  0.20619385 0.6422738 ] 4\n",
      "[0.02131354 0.00380459 0.1348034  0.81913534 0.02094313] 3\n",
      "[0.00730056 0.02320506 0.00825509 0.95464947 0.00658983] 3\n",
      "[0.12315168 0.00567728 0.80841179 0.04407472 0.01868452] 3\n",
      "[0.02576058 0.0063406  0.95157755 0.00667839 0.00964288] 2\n",
      "[0.20671721 0.20668239 0.08844017 0.05887055 0.43928969] 1\n",
      "[0.00247052 0.00249262 0.98518159 0.00245457 0.00740069] 2\n",
      "[0.03900178 0.04461704 0.16073936 0.03422922 0.72141261] 3\n",
      "[1.64277443e-04 5.08697701e-04 1.69996881e-03 9.91856442e-01\n",
      " 5.77061396e-03] 3\n",
      "[0.08807758 0.79680469 0.01264633 0.0424169  0.06005451] 1\n",
      "[0.03297028 0.75743978 0.02513453 0.10560274 0.07885268] 1\n",
      "[0.25559518 0.33485729 0.06191562 0.04621424 0.30141767] 0\n",
      "[0.77874343 0.02695856 0.14136901 0.0053919  0.04753711] 0\n",
      "[0.00498011 0.01138327 0.00986244 0.65897047 0.31480372] 4\n",
      "[0.86453844 0.00625009 0.08288379 0.03603972 0.01028796] 0\n",
      "[0.01103557 0.49794882 0.07440674 0.25347783 0.16313103] 1\n",
      "[0.04981217 0.88109798 0.0130466  0.00874706 0.04729619] 1\n",
      "[0.01235483 0.23100216 0.0533933  0.63137499 0.07187471] 3\n",
      "[0.01662665 0.96170801 0.00250446 0.00514196 0.01401891] 1\n",
      "[0.0135082  0.13239919 0.00566052 0.09248619 0.7559459 ] 4\n",
      "[0.60378553 0.08989682 0.02796417 0.12028647 0.158067  ] 0\n",
      "[0.93136092 0.00633198 0.03089641 0.01352723 0.01788346] 0\n",
      "[0.05531505 0.10162836 0.0083304  0.15230868 0.68241751] 4\n",
      "[0.0045911  0.00863047 0.63844548 0.33021602 0.01811692] 2\n",
      "[0.92791038 0.03362906 0.00393505 0.00136028 0.03316524] 0\n",
      "[0.16413535 0.74571495 0.03112987 0.00486981 0.05415003] 1\n",
      "[0.77664156 0.10570201 0.00952778 0.05151983 0.05660882] 0\n",
      "[0.51966695 0.2670569  0.01496796 0.03434298 0.16396521] 0\n",
      "[0.0066294  0.93751433 0.00331973 0.00568815 0.04684839] 1\n",
      "[0.46513487 0.01072321 0.08501129 0.42426693 0.0148637 ] 0\n",
      "[0.00225087 0.95027681 0.00109965 0.00745163 0.03892104] 1\n",
      "[0.00775882 0.93185683 0.00266684 0.00448492 0.05323258] 1\n",
      "[0.04308215 0.26534647 0.23282795 0.16061802 0.29812541] 1\n",
      "[0.0047754  0.01918313 0.06234145 0.87919077 0.03450924] 3\n",
      "[0.82146499 0.04257243 0.04912137 0.01029708 0.07654412] 0\n",
      "[9.09392315e-04 3.79869957e-02 2.08581008e-03 9.11334709e-01\n",
      " 4.76830931e-02] 3\n",
      "[0.14580315 0.69350434 0.04879612 0.05142296 0.06047342] 1\n",
      "[0.01984971 0.0255101  0.00652059 0.75418559 0.19393401] 3\n",
      "[0.00801956 0.01814012 0.23514582 0.62166487 0.11702963] 3\n",
      "[0.03912423 0.00418435 0.92256081 0.01147862 0.02265199] 2\n",
      "[0.08598561 0.12606074 0.53997395 0.02736384 0.22061586] 2\n",
      "[0.01152484 0.25719585 0.01773162 0.04849948 0.66504821] 4\n",
      "[0.02881164 0.05705844 0.73402662 0.09588788 0.08421543] 2\n",
      "[0.00435594 0.00336798 0.00647779 0.96078207 0.02501622] 3\n",
      "[0.04413802 0.86444977 0.00931543 0.02417604 0.05792074] 1\n",
      "[0.05904233 0.00238135 0.90514507 0.02081368 0.01261757] 2\n",
      "[0.95807393 0.0067947  0.00594091 0.00718421 0.02200624] 0\n",
      "[0.0070735  0.93658212 0.00502391 0.01074881 0.04057167] 1\n",
      "[0.16781226 0.70255897 0.01463909 0.00704334 0.10794635] 1\n",
      "[0.93684617 0.01102436 0.00641769 0.02996835 0.01574343] 0\n",
      "[0.10522926 0.48164672 0.03559568 0.15255148 0.22497687] 1\n",
      "[0.07631205 0.04197574 0.75262734 0.02936501 0.09971986] 2\n",
      "[0.04598184 0.0256519  0.71480186 0.03690559 0.17665881] 2\n",
      "[0.00714137 0.01238299 0.69685544 0.2560038  0.02761641] 2\n",
      "[0.03425573 0.33712189 0.07989975 0.33921887 0.20950376] 3\n",
      "[0.95403278 0.00785831 0.01262626 0.00646276 0.01901988] 0\n",
      "[0.97902113 0.00282567 0.00713372 0.00289825 0.00812123] 0\n",
      "[0.04525047 0.52078235 0.0867499  0.12351934 0.22369793] 1\n",
      "[0.04059465 0.50508013 0.16798009 0.02609253 0.2602526 ] 1\n",
      "[0.05042308 0.00680876 0.7681315  0.07550736 0.0991293 ] 2\n",
      "[0.02757106 0.04421754 0.50833435 0.36854308 0.05133399] 3\n",
      "[0.01794776 0.76311548 0.00890924 0.01098097 0.19904655] 1\n",
      "[0.66540883 0.02396491 0.23158839 0.06040615 0.01863171] 0\n",
      "[0.53256632 0.31881109 0.01154616 0.01033857 0.12673787] 1\n",
      "[0.04778808 0.50772356 0.04991496 0.04966156 0.34491184] 1\n"
     ]
    }
   ],
   "source": [
    "pred_probas = clf.predict_proba(features_test)\n",
    "\n",
    "for i in range(len(predicted_labels)):\n",
    "    print(pred_probas[i], labels_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. For a set of regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Load all available training features into one big dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['borde_rural', 'borde_soacha', 'mixco_3', 'mixco_1_and_ebenezer', 'dennery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['id', 'features', 'label']\n",
    "df_train_global = pd.DataFrame(columns=columns)\n",
    "\n",
    "pickle_path = join('..', '..', 'pickles')\n",
    "for region in regions:\n",
    "    try:\n",
    "        with open(join(pickle_path, 'resnet50_avg_retrained_features_' + region + '_train.pkl'), 'rb') as f:\n",
    "            df_train = pickle.load(f)\n",
    "            df_train_global = pd.concat([df_train_global, df_train], ignore_index=True)\n",
    "    except:\n",
    "        print(\"Error reading training data for region \", region)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>features</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7a37c004</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.955824, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7a43cf34</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.2254369,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7a2beb9e</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.5360031,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7a30cd44</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.9002078, 0.0, 0.0, 0.1847459...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7a26b840</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           features label\n",
       "0  7a37c004  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.955824, ...     0\n",
       "1  7a43cf34  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.2254369,...     0\n",
       "2  7a2beb9e  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.5360031,...     0\n",
       "3  7a30cd44  [0.0, 0.0, 0.0, 0.9002078, 0.0, 0.0, 0.1847459...     0\n",
       "4  7a26b840  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_global.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_global.features[13000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Expand the dataframe such that instead of a list of features, every feature has its one column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_train = df_train_global.features.apply(lambda features: pd.Series(list(features)))\n",
    "#features_train\n",
    "\n",
    "#features_train = df_train_global.features.apply(lambda x: pd.Series(list(x)))\n",
    "#features_train = features_train.astype('double')\n",
    "\n",
    "feature_matrix_global = df_train_global['features'].to_numpy()\n",
    "feature_matrix_global = np.column_stack(feature_matrix_global).transpose()\n",
    "\n",
    "labels_global = df_train_global['label'].to_numpy().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(feature_matrix_global)\n",
    "feature_matrix_scaled = scaler.transform(feature_matrix_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14853, 2048)\n",
      "(14853,)\n"
     ]
    }
   ],
   "source": [
    "print(feature_matrix_global.shape)\n",
    "print(labels_global.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train an SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma='scale', probability=True, C=100, decision_function_shape='ovr', verbose=1)\n",
    "clf.fit(feature_matrix_global, labels_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(join(pickle_path, 'classifier_resnet50_avg_retrained_all_scaled.pkl' ), 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train a Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=32, random_state=0)\n",
    "clf.fit(feature_matrix_global, labels_global) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for elem in a[:-3]:\n",
    "    print(elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
