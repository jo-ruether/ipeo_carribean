\relax 
\citation{Chen2012}
\citation{Soman2019}
\citation{Yudin2018}
\citation{Shreve2017}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction (Context and Challenges)}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Context}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Open AI Challenge}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Previous Work}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Thumbnail of stitched drone image from Dennery, St.Lucia.\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:thumbnail_dennery}{{1}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Data Description}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Images}{2}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces General information about provided data.\relax }}{2}}
\newlabel{tab:general}{{1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Labels}{2}}
\citation{resnet}
\citation{inceptionv3}
\citation{densenet}
\citation{vgg}
\citation{imagenet}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Example images for each material class. (Scales differ)\relax }}{3}}
\newlabel{fig:mat_examples}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Data Noise}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed Processing Routine}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Petrained Neural Network as Feature Extractor}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces (a) and (b) named differently due to incoherent labeling of rusty roofs. Similarly unclear boundary between "irregular metal" and "incomplete" ((d) and (e)). Obvious labeling error in (c).\relax }}{4}}
\newlabel{fig:ambiguities}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Pixel-based Baseline }{4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Proposed processing routine: The classification part of a pretrained neural network is removed, leaving the feature extraction. A SVM or RF is used to build a model out of the training features and the groundtruth labels in an iterative process. Test features are fed into this model to predict labels and determine prediction confidence.\relax }}{5}}
\newlabel{fig:flowchart}{{4}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Original image classified as "other" with red, green and blue individual channels (top row).   Gradient images of each channel (bottom row)\relax }}{5}}
\newlabel{fig:pixel_based}{{5}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Confusion Matrices\relax }}{6}}
\newlabel{fig:pixel_based_cm}{{6}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Log-loss on online challenge test set for feature extraction with different pretrained models. Classification was always performed with an SVM.\relax }}{6}}
\newlabel{tab:model_comparison}{{2}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Performance metrics of best-performing pixel-based and suggested processing routines\relax }}{6}}
\newlabel{tab:pb_vs_nn}{{3}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Pixel-based Baseline}{6}}
\bibdata{ipeo}
\bibcite{Chen2012}{1}
\bibcite{Soman2019}{2}
\bibcite{Yudin2018}{3}
\bibcite{Shreve2017}{4}
\bibcite{resnet}{5}
\bibcite{inceptionv3}{6}
\bibcite{densenet}{7}
\bibcite{vgg}{8}
\bibcite{imagenet}{9}
\bibstyle{ieeetr}
\@writefile{toc}{\contentsline {section}{\numberline {5}Discussion}{7}}
\newlabel{sec:discussion}{{5}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Appendix}{7}}
