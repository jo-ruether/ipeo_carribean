\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{tabularx}
\usepackage{subcaption} 
\usepackage{textcomp}
\usepackage{caption}
\usepackage{graphicx}
\usepackage[top=0.8in, bottom=0.8in, left=0.8in, right=0.8in]{geometry}
% Add other packages here %

\usepackage{epstopdf}
\epstopdfDeclareGraphicsRule{.tif}{png}{.png}{convert #1 \OutputFile}
\AppendGraphicsExtensions{.tif}

% Put your group number and names in the author field %
\title{\bf{Classifying Roof Material From Drone Imagery} \\
 An Approach to the Open AI Caribbean Challenge}
\author{Johannes Leonhard Ruether}


% N.B.: The report should not be longer than 3 pages 

\begin{document}
	\maketitle
	
	\section{Introduction (Context and Challenges)}
	
	\subsection{Context}
	
	Regions like the Carribean are regularly hit by rainstorms, floods or earthquakes. Despite being so prone, many houses in those areas are unable to withstand these natural hazards due to poor construction quality. This exposes their inhabitants to a great risk of becoming homeless during the next disaster. 
	
	International programs as the World Bank's Global Program for Resilient Housing are making attempts to retrofit houses to the natural forces they are exposed to. In these large and often informal settlements it is difficult to assess which houses pose especially high risks due to their construction or are damaged and need repair. Exploring these areas on the ground is time consuming and costly. 
	This is why the possibilities of image processing for automatic recognition of vulnerable houses on the basis of drone imagery is explored. Such a technology could assist building inspectors and narrow down large areas to those that are worth a closer inspection on the ground. 
	The material that roofs are made up of is a central indicator of how well a house is prepared against natural disasters. Therefore, classifying roof material from aerial images is a key step to identify precarious houses. \\
	
	\subsection{Open AI Challenge}
	
	The above background led to the initiation of the \textit{Open AI Caribbean Challenge: Mapping Disaster Risk from Aerial Imagery}, which was conducted in between October and December 2020 on \textit{drivendata.org}.	
	This report describes an approach to solve this challenge.\\
	
	\textbf{Probabilities instead of hard labels}
	
	\subsection{Previous Work}
	
	In many applications, the identification of roofs is considered useful. Roof segmentation is often done with LiDAR data, as presented in \cite{Chen2012}. Other papers such as \cite{Soman2019} have successfully attempted roof segmentation using only drone imagery, which is less costly. This step will become relevant for the task at hand. The approach discussed in this report however uses images of roofs that have already been segmented.\\
	
	The identification of roof defects has been addressed in previous works, e.g. \cite{Yudin2018}, in which water stagnation on roofs is measured. Multiple patents such as (e.g. \cite{Shreve2017}) employ aerial images to evaluate damage on individual roofs for insurance purposes. To my best knowledge, academic works on roof material and condition classification from drone imagery on a large scale have not been published. 
	
	\section{Data Description}
	
	\subsection{Images}
		
	\begin{figure}
		\centering		
		\includegraphics[width=0.8\textwidth]{figures/thumbnail_dennery.png}
		\caption{Thumbnail of stitched drone image from Dennery, St.Lucia.}
		\label{fig:thumbnail_dennery}
	\end{figure}

	The data provided for the challenge consists of high resolution (~4cm) drone imagery of five patches of land: two from Soacha, Colombia, two from Mixco, Guatemala and one from Dennery (St. Lucia).
	For every region, there is one stitched cloud-optimized GeoTIFF file, ranging from 500 to 1800 Megapixels in size. A thumbnail of the Dennery settlement is shown as example in Fig.~\ref{fig:thumbnail_dennery}.\\
	General information about the images is summarized in Table~\ref{tab:general}

	\begin{center}
		\bgroup
		\def\arraystretch{1.1}
		\begin{tabular}{ | m{5cm} | m{10cm}|} 
			\hline
			Platform & WeRobotics (private drone)  \\ 
			\hline
			Source & DrivenData Competition \newline https://www.drivendata.org/competitions/58/disaster-response-roof-type/data/ \\ 
			\hline
			Acquisition Method & Drone Photography  \\ 
			\hline
			SRS  & Ellipsoid (EPSG:32616, 32618, 326120)  \\ 
			\hline
			Spatial/Spectral resolution & 3.8-4.5cm, RGB  \\ 
			\hline
			Type of Product & Cloud-optimized GeoTIFF \\ 
			\hline
		\end{tabular}
		\egroup		
		\captionof{table}{General information about provided data.} 
		\label{tab:general}
	\end{center}
	
	\subsection{Labels}
	
	Roofs are labeled as one of five classes, examples of which are given in Fig.~\ref{fig:mat_examples}: 
	
	\begin{enumerate}
		\itemsep0em
		\item Concrete and Cement (1385 training samples): Roofs made out of concrete or cement.
		\item Healthy Metal (7370): Roofs of metal that are intact but may be corrugated or galvanized.
		\item Incomplete (668): Roofs that are severely damaged or under construction.
		\item Irregular Metal (5236): Roofs that are slightly damaged, rusted or patched.
		\item Other (193): Roofs that do not fit into other categories (include tiles, red painted, other materials).
	\end{enumerate}

	\begin{figure}
		
		\centering
		\begin{subfigure}[c]{0.32\textwidth}
			\includegraphics[width=0.47\textwidth]{figures/mat_examples/conc1.png}		
			\includegraphics[width=0.47\textwidth]{figures/mat_examples/conc2.png}
			\subcaption{Concrete/Cement}
		\end{subfigure}
		\begin{subfigure}[c]{0.32\textwidth}
			\includegraphics[width=0.47\textwidth]{figures/mat_examples/hm1.png}		
			\includegraphics[width=0.47\textwidth]{figures/mat_examples/hm2.png}
			\subcaption{Healthy Metal}
		\end{subfigure}
		\begin{subfigure}[c]{0.32\textwidth}
			\includegraphics[width=0.47\textwidth]{figures/mat_examples/inc1.png}		
			\includegraphics[width=0.47\textwidth]{figures/mat_examples/inc2.png}
			\subcaption{Incomplete}
		\end{subfigure}
		\begin{subfigure}[c]{0.32\textwidth}
			\includegraphics[width=0.32\textwidth]{figures/mat_examples/irr1.png}		
			\includegraphics[width=0.32\textwidth]{figures/mat_examples/irr2.png}
			\subcaption{Irregular Metal}
		\end{subfigure}
		\begin{subfigure}[c]{0.32\textwidth}
			\centering
			\includegraphics[width=0.35\textwidth]{figures/mat_examples/other1.png}		
			\includegraphics[width=0.45\textwidth]{figures/mat_examples/other2.png}
			\subcaption{Other}
		\end{subfigure}
	\caption{Example images for each material class. (Scales differ)}
	\label{fig:mat_examples}
	\end{figure}

	\subsection{Data Noise}
	
	Class membership is unfortunately sometimes ambiguous in the provided groundtruth data. 
	First, labels are sometimes used inconsistently. This is especially true for "irregular" and "healthy metal". Where rusty roofs should be labeled as "irregular", many of them get a "healthy metal" label.
	Moreover there is confusion about features that make a roof "irregular" or "incomplete".
	These inconsistencies might stem from different annotators labeling images.
	
	Second, labels are sometimes clearly incorrect, e.g. concrete roofs are labeled as "healthy metal". Some regions seems to be annotated with more care than others. 
	
	It is impossible to quantify the extent to which annotations are noisy. 
	Some examples of these ambiguities are shown in Fig.~\ref{fig:ambiguities}.
	The implications for the results are discussed in section~\ref{sec:discussion}.
	
	\begin{figure}
		\centering
		\begin{subfigure}[c]{0.31\textwidth}
			\centering
			\includegraphics[width=.72\textwidth]{figures/wrong_labels/hm_rusty.png}
			\subcaption{"healthy metal"}	
		\end{subfigure}	
		\begin{subfigure}[c]{0.31\textwidth}
			\centering
			\includegraphics[width=.72\textwidth]{figures/wrong_labels/irr_rusty.png}
			\subcaption{"irregular metal"}
		\end{subfigure}
		\begin{subfigure}[c]{0.31\textwidth}
			\centering
			\includegraphics[width=.9\textwidth]{figures/wrong_labels/hm_should_be_conc.png}
			\subcaption{Labeled "irregular metal" where clearly concrete}
		\end{subfigure}
		\vspace{.3cm}]
		\begin{subfigure}[c]{0.4\textwidth}
			\centering
			\includegraphics[width=0.67\textwidth]{figures/wrong_labels/irr_holes.png}
			\subcaption{Labeled "irregular metal"}
		\end{subfigure}
		\begin{subfigure}[c]{0.4\textwidth}
			\centering		
			\includegraphics[width=0.72\textwidth]{figures/wrong_labels/inc_holes.png}
			\subcaption{Labeled "incomplete"}
		\end{subfigure}
		\caption{(a) and (b) named differently due to incoherent labeling of rusty roofs. Similarly unclear boundary between "irregular metal" and "incomplete" ((d) and (e)). Obvious labeling error in (c).}
		\label{fig:ambiguities}
	\end{figure}

	
	\section{Proposed Processing Routine}
	
	\subsection{Petrained Neural Network as Feature Extractor}		
	
	The proposed processing routine uses a pretrained neural network as feature extractor. Different publicly available architectures were tested, such as ResNet50~\cite{resnet}, InceptionV3~\cite{inceptionv3}, DenseNet201~\cite{densenet} and VGG16~\cite{vgg}. The employed pretrained architectures were trained on more than a million images of 1000 categories from the ImageNet database ~\cite{imagenet}. 
	ImageNet is a collection of natural images of common objects and animals. The features which are relevant to distinguish those classes, are very likely also relevant to discriminate other types of natural images, such as roofs.
	In order to obtain features, the classification layer is removed and replaced by an average or maximum pooling layer to reduce the number of features.\\	
	
	In the next step, a Support Vector Machine (SVM) or Random Forest (RF) is trained to classify roof materials based on the extracted features. The calculated classification can then be used to predict class membership based on features of test samples. For the context of the challenge, prediction probabilities needed to be calculated. The \textit{scikit-learn} implementation of both SVM and RF provide pseudo-probabilities that take a samples' distance to the decision boundary into account. Those probabilities/confidences were submitted for evaluation on the challenge website.
	The full classification pipeline is presented in Fig.~\ref{fig:flowchart}.
	
	
	\begin{figure}
		\centering		
		\includegraphics[width=0.8\textwidth]{figures/flowchart.pdf}
		\caption{Proposed processing routine: The classification part of a pretrained neural network is removed, leaving the feature extraction. A SVM or RF is used to build a model out of the training features and the groundtruth labels in an iterative process. Test features are fed into this model to predict labels and determine prediction confidence.}
		\label{fig:flowchart}
	\end{figure}

	\subsection{Pixel-based Baseline } 
	As a baseline for comparison, several statistical metrics are extracted as features and classified with a SVM. The mean is used to assess the dominant colors on a roof. Heterogeneity is tried to measure using the standard deviation and range of every image. Every metric is calculated on every color channel and on the absolute of the Sobel-filtered image in x- and y-direction of every color channel (see Fig.~\ref{fig:pixel_based}). This results in a 18-dimensional feature vector (3 metrics $\times$ 3 channels on original and gradient image).
	
	\begin{figure}
		\centering
		\begin{subfigure}[t]{\textwidth}
			\centering
			\includegraphics[width=\textwidth, trim={3cm 3cm 3cm 3cm},clip]{figures/pixel_based/rgb_channels.png}
			\subcaption{RGB Image and individual color channels}
		\end{subfigure}
		\begin{subfigure}[b]{.8\textwidth}
			\includegraphics[width=.95\textwidth, trim={2cm 1.5cm 2cm 1.5cm},clip]{figures/pixel_based/sobel.png}
			\subcaption{Derivative images (absolute of Sobel-filtered images in x- and y-direction)}
		\end{subfigure}
		\caption{Original image classified as "other" with red, green and blue individual channels (top row). \\ Gradient images of each channel (bottom row)}
		\label{fig:pixel_based}
	\end{figure}
	
	\section{Results}
	
	Best results obtained with average pooling instead of Max
	All with SVM, C=100
	
	More data was better -> no improvement when handpicking because test set was noisy as well.
	
	\begin{center}
		\bgroup
		\def\arraystretch{1.1}
		\begin{tabular}{ | m{5cm} | m{2cm} | } 
			
			\hline
			Pretrained model & Log-loss \\
			\hline
			\hline
			ResNet50 & 0.5554 \\
			\hline
			InceptionV3 & 0.5917\\
			\hline
			DenseNet201 & 0.5800\\
			\hline
			VGG16 & 0.6152\\
			\hline
		\end{tabular}
		\egroup
		\captionof{table}{Log-loss on online challenge test set for feature extraction with different pretrained models. Classification was always performed with an SVM.} 
		\label{tab:model_comparison}
	\end{center}
	
	
	\begin{center}
		\bgroup
		\def\arraystretch{1.1}
		\begin{tabular}{ | m{5cm} | m{2cm} | m{2cm} | m{2cm} |} 
			
			\hline
			Method & Log-loss & Accuracy & Micro-F1 \\
			\hline
			\hline
			Pixel-based features + SVM & & &  \\
			\hline
			Pixel-based features + RF & & &  \\
			\hline
			ResNet50 + SVM & & &  \\
			\hline
			ResNet50 + RF & & &  \\
			\hline
		\end{tabular}
		\egroup
		\captionof{table}{Performance metrics of best-performing pixel-based and suggested processing routines} 
		\label{tab:pb_vs_nn}
	\end{center}
	
	
	
	Confusion matrices for one split but for the same split
	\subsection{Pixel-based Baseline}
	
	\begin{figure}
		\begin{subfigure}[t]{.5\textwidth}
			\centering
			\includegraphics[width=0.9\textwidth]{figures/results/pixel_based_cm.png}
			\caption{Pixel-based features classified by SVM}
		\end{subfigure}
		\begin{subfigure}[t]{.5\textwidth}
			\centering
			\includegraphics[width=0.9\textwidth]{figures/results/nn_based_cm.png}
			\caption{ResNet50 features classified by SVM}
		\end{subfigure}
	\caption{Confusion Matrices}
	\label{fig:pixel_based_cm}
	\end{figure}
	
	One example confusion matrix for NN and PB
	
	Accuracy and F1-score
	
	Map with colored rectangles indicating roof security
	
	The proposed processing routine was designed to achieve good results in terms of log-loss.
	
	\textbf{Calculate the log loss!!}
	
	
	Results qualitative (e.g. maps) and quantitative (e.g. accuracies, statistics). /!\ This implies that you have either access to groundtruth data or digitized/photointerpreted some areas in order to compute accuracies.
	
	
	\section{Discussion}
	\label{sec:discussion}
	Discussion where you are critical about what has been done and what could be further explored. You have investigated a topic and achieving your initial goal is not always possible in a fixed time frame, however you should be able to assess your situation and what should then be done/improved in order to reach your goal.
	
	Outlook: Retrain network
	
	
	!!!Noisy Data!!!
	
	\section{Appendix}
	APPENDIX: Include your scripts (Matlab, GoogleEarthEngine or others) and the specific functions you used in QGIS (if applicable)
	*Include a descriptive header on your different scripts
	* Comment your code, use indentation and spacing
	* Only keep the code you used for your latest results
	
	
	
	\bibliography{ipeo} 
	
	\bibliographystyle{ieeetr}

\end{document}